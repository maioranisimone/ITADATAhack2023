{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "df = pd.read_csv('dataset_challenge_DAY1/train_set.csv')\n",
    "test = pd.read_csv('dataset_challenge_DAY1/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the main dataframe to 'train'\n",
    "train = df\n",
    "\n",
    "# Remove numbers from the rows in the 'Text' column of 'train'\n",
    "train['Text'] = train['Text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "# Remove numbers from the rows in the 'Text' column of 'test'\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub(r'\\d+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'train'\n",
    "train['Text'] = df['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "\n",
    "# Remove punctuation and convert text to lowercase in the 'Text' column of 'test'\n",
    "test['Text'] = test['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of English stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Remove stopwords from the 'Text' column in 'train'\n",
    "train['Text'] = train['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Remove stopwords from the 'Text' column in 'test'\n",
    "test['Text'] = test['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer to convert the text of the law into a matrix of TF-IDF features\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the TF-IDF vectorizer on the 'Text' column in 'train'\n",
    "train_tfidf = tfidf.fit_transform(train['Text'])\n",
    "\n",
    "# Transform the 'Text' column in 'test' into TF-IDF features without refitting the vectorizer\n",
    "test_tfidf = tfidf.transform(test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the train dataset using a Neural Network (MLPClassifier)\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=10, random_state=42, verbose=True)\n",
    "\n",
    "# Fit the Neural Network model on the TF-IDF features from the train dataset and predict 'Directory code'\n",
    "nn.fit(train_tfidf, train['Directory code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained Neural Network model to predict the test dataset\n",
    "y_pred = nn.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a new CSV file with one column named 'predictions'\n",
    "with open('predictions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row with the column name 'label'\n",
    "    writer.writerow([\"label\"])\n",
    "    \n",
    "    # Write each prediction value from 'y_pred' into the 'label' column\n",
    "    for i in range(len(y_pred)):\n",
    "        writer.writerow([y_pred[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
