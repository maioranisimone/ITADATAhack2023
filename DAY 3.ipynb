{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "train = pd.read_csv('dataset_challenge_DAY3/train_set.csv')\n",
    "test = pd.read_csv('dataset_challenge_DAY3/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable 'y_train' containing the target labels by dropping specified columns from 'train'\n",
    "y_train = train.drop(['CELEX_ID', 'Text', 'Citations'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text cleaning function that extracts a substring from the input text\n",
    "def take_some_text(text):\n",
    "    text = text[149:8000]  # Extract a substring from index 149 to 7999\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove stopwords and punctuation from a text column in a dataframe\n",
    "def remove_stopwords_and_punkt(df, text_column=\"text\", legal_stopwords=False):\n",
    "    # This function takes as input a dataframe, a string containing the text column name, and an optional list of legal words.\n",
    "    # The function returns a dataframe with the specified text column cleaned from stopwords and punctuation.\n",
    "    nltk.download('stopwords')  # Download the NLTK stopwords dataset\n",
    "    nltk.download('punkt')      # Download the NLTK punctuation dataset\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))  # Create a set of English stopwords\n",
    "    \n",
    "    if not legal_stopwords == False:\n",
    "        stop_words = stop_words.union(legal_stopwords)  # If legal stopwords are provided, add them to the set\n",
    "    \n",
    "    def remove_stop_words(text):\n",
    "        words = word_tokenize(text.lower())          # Tokenize the text and convert to lowercase\n",
    "        clean_words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "        \n",
    "        return \" \".join(clean_words)  # Join the clean words back into a string\n",
    "    \n",
    "    df[text_column] = df[text_column].apply(remove_stop_words)  # Apply the remove_stop_words function to the text column\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove punctuation and convert text to lowercase in a dataframe column\n",
    "def remove_punct(df):\n",
    "    # Apply lambda function to remove punctuation and convert text to lowercase in the 'Text' column\n",
    "    df['Text'] = df['Text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "    \n",
    "    return df['Text']  # Return the cleaned 'Text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove digits from text in a dataframe column\n",
    "def remove_digit(df):\n",
    "    # Apply regex to remove digits from the 'Text' column\n",
    "    df['Text'] = df['Text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "    \n",
    "    return df['Text']  # Return the text column with digits removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove specified symbols from text in a dataframe column\n",
    "def remove_symbols(df):\n",
    "    symbols_to_remove = ['/', '$', '@', '\\\\', '\\.+']  # List of symbols to remove\n",
    "    pattern = '|'.join(re.escape(symbol) for symbol in symbols_to_remove)  # Create a regex pattern\n",
    "    \n",
    "    # Apply regex to remove specified symbols from the 'Text' column\n",
    "    df['Text'] = df['Text'].apply(lambda x: re.sub(pattern, '', x))  \n",
    "    \n",
    "    return df['Text']  # Return the text column with specified symbols removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simonemaiorani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/simonemaiorani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Apply various text cleaning functions to the 'Text' column in the train set\n",
    "X_train = remove_stopwords_and_punkt(train, text_column=\"Text\")  # Remove stopwords and punctuation\n",
    "X_train['Text'] = train['Text'].apply(take_some_text)  # Extract a substring\n",
    "X_train['Text'] = remove_digit(train)  # Remove digits\n",
    "X_train['Text'] = remove_symbols(train)  # Remove specified symbols\n",
    "X_train['Text'] = remove_punct(train)  # Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simonemaiorani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/simonemaiorani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Apply various text cleaning functions to the 'Text' column in the test set\n",
    "test = remove_stopwords_and_punkt(test, text_column=\"Text\")  # Remove stopwords and punctuation\n",
    "test['Text'] = test['Text'].apply(take_some_text)  # Extract a substring\n",
    "test['Text'] = remove_digit(test)  # Remove digits\n",
    "test['Text'] = remove_symbols(test)  # Remove specified symbols\n",
    "test['Text'] = remove_punct(test)  # Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer for text\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the TF-IDF vectorizer on the 'Text' column in the train dataset\n",
    "X_train_idf_final = tfidf.fit_transform(train['Text'])\n",
    "\n",
    "# Transform the 'Text' column in the test dataset using the pre-fitted vectorizer\n",
    "X_test_idf_final = tfidf.transform(test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07462042\n",
      "Iteration 2, loss = 0.00422734\n",
      "Iteration 3, loss = 0.00332522\n",
      "Iteration 4, loss = 0.00217096\n",
      "Iteration 5, loss = 0.00118655\n",
      "Iteration 6, loss = 0.00067113\n",
      "Iteration 7, loss = 0.00041366\n",
      "Iteration 8, loss = 0.00034698\n",
      "Iteration 9, loss = 0.00030360\n",
      "Iteration 10, loss = 0.00026066\n",
      "Iteration 11, loss = 0.00024162\n",
      "Iteration 12, loss = 0.00022239\n",
      "Iteration 13, loss = 0.00020702\n",
      "Iteration 14, loss = 0.00019510\n",
      "Iteration 15, loss = 0.00018482\n",
      "Iteration 16, loss = 0.00017700\n",
      "Iteration 17, loss = 0.00016932\n",
      "Iteration 18, loss = 0.00016290\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07836418\n",
      "Iteration 2, loss = 0.01178027\n",
      "Iteration 3, loss = 0.00842916\n",
      "Iteration 4, loss = 0.00505814\n",
      "Iteration 5, loss = 0.00249807\n",
      "Iteration 6, loss = 0.00125523\n",
      "Iteration 7, loss = 0.00080760\n",
      "Iteration 8, loss = 0.00057395\n",
      "Iteration 9, loss = 0.00046266\n",
      "Iteration 10, loss = 0.00039478\n",
      "Iteration 11, loss = 0.00033442\n",
      "Iteration 12, loss = 0.00030444\n",
      "Iteration 13, loss = 0.00027920\n",
      "Iteration 14, loss = 0.00026017\n",
      "Iteration 15, loss = 0.00024418\n",
      "Iteration 16, loss = 0.00023169\n",
      "Iteration 17, loss = 0.00022196\n",
      "Iteration 18, loss = 0.00020966\n",
      "Iteration 19, loss = 0.00020295\n",
      "Iteration 20, loss = 0.00019423\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07266296\n",
      "Iteration 2, loss = 0.00226412\n",
      "Iteration 3, loss = 0.00145762\n",
      "Iteration 4, loss = 0.00090099\n",
      "Iteration 5, loss = 0.00054963\n",
      "Iteration 6, loss = 0.00042087\n",
      "Iteration 7, loss = 0.00035622\n",
      "Iteration 8, loss = 0.00031159\n",
      "Iteration 9, loss = 0.00027829\n",
      "Iteration 10, loss = 0.00025687\n",
      "Iteration 11, loss = 0.00022875\n",
      "Iteration 12, loss = 0.00021680\n",
      "Iteration 13, loss = 0.00020045\n",
      "Iteration 14, loss = 0.00018924\n",
      "Iteration 15, loss = 0.00018043\n",
      "Iteration 16, loss = 0.00017094\n",
      "Iteration 17, loss = 0.00016272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07253848\n",
      "Iteration 2, loss = 0.00449445\n",
      "Iteration 3, loss = 0.00366220\n",
      "Iteration 4, loss = 0.00261151\n",
      "Iteration 5, loss = 0.00142408\n",
      "Iteration 6, loss = 0.00067998\n",
      "Iteration 7, loss = 0.00046683\n",
      "Iteration 8, loss = 0.00037681\n",
      "Iteration 9, loss = 0.00031907\n",
      "Iteration 10, loss = 0.00027991\n",
      "Iteration 11, loss = 0.00025361\n",
      "Iteration 12, loss = 0.00023485\n",
      "Iteration 13, loss = 0.00021759\n",
      "Iteration 14, loss = 0.00020439\n",
      "Iteration 15, loss = 0.00019387\n",
      "Iteration 16, loss = 0.00018468\n",
      "Iteration 17, loss = 0.00017701\n",
      "Iteration 18, loss = 0.00016995\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.21070898\n",
      "Iteration 2, loss = 0.03992708\n",
      "Iteration 3, loss = 0.01731475\n",
      "Iteration 4, loss = 0.00801604\n",
      "Iteration 5, loss = 0.00416605\n",
      "Iteration 6, loss = 0.00238193\n",
      "Iteration 7, loss = 0.00171815\n",
      "Iteration 8, loss = 0.00134689\n",
      "Iteration 9, loss = 0.00134385\n",
      "Iteration 10, loss = 0.00073969\n",
      "Iteration 11, loss = 0.00078830\n",
      "Iteration 12, loss = 0.00069102\n",
      "Iteration 13, loss = 0.00077668\n",
      "Iteration 14, loss = 0.00060726\n",
      "Iteration 15, loss = 0.00049220\n",
      "Iteration 16, loss = 0.00043010\n",
      "Iteration 17, loss = 0.00040490\n",
      "Iteration 18, loss = 0.00038736\n",
      "Iteration 19, loss = 0.00037372\n",
      "Iteration 20, loss = 0.00035950\n",
      "Iteration 21, loss = 0.00034864\n",
      "Iteration 22, loss = 0.00033709\n",
      "Iteration 23, loss = 0.00032826\n",
      "Iteration 24, loss = 0.00032002\n",
      "Iteration 25, loss = 0.00031159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07827722\n",
      "Iteration 2, loss = 0.00758538\n",
      "Iteration 3, loss = 0.00499029\n",
      "Iteration 4, loss = 0.00298741\n",
      "Iteration 5, loss = 0.00153678\n",
      "Iteration 6, loss = 0.00084315\n",
      "Iteration 7, loss = 0.00066982\n",
      "Iteration 8, loss = 0.00055463\n",
      "Iteration 9, loss = 0.00045796\n",
      "Iteration 10, loss = 0.00039316\n",
      "Iteration 11, loss = 0.00036244\n",
      "Iteration 12, loss = 0.00032432\n",
      "Iteration 13, loss = 0.00029204\n",
      "Iteration 14, loss = 0.00026756\n",
      "Iteration 15, loss = 0.00025615\n",
      "Iteration 16, loss = 0.00023330\n",
      "Iteration 17, loss = 0.00022080\n",
      "Iteration 18, loss = 0.00020955\n",
      "Iteration 19, loss = 0.00020012\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.14577478\n",
      "Iteration 2, loss = 0.02198209\n",
      "Iteration 3, loss = 0.01092803\n",
      "Iteration 4, loss = 0.00665589\n",
      "Iteration 5, loss = 0.00435896\n",
      "Iteration 6, loss = 0.00364047\n",
      "Iteration 7, loss = 0.00261347\n",
      "Iteration 8, loss = 0.00204403\n",
      "Iteration 9, loss = 0.00174423\n",
      "Iteration 10, loss = 0.00134607\n",
      "Iteration 11, loss = 0.00122470\n",
      "Iteration 12, loss = 0.00094313\n",
      "Iteration 13, loss = 0.00069237\n",
      "Iteration 14, loss = 0.00060862\n",
      "Iteration 15, loss = 0.00058512\n",
      "Iteration 16, loss = 0.00054620\n",
      "Iteration 17, loss = 0.00047947\n",
      "Iteration 18, loss = 0.00040678\n",
      "Iteration 19, loss = 0.00038729\n",
      "Iteration 20, loss = 0.00036060\n",
      "Iteration 21, loss = 0.00033207\n",
      "Iteration 22, loss = 0.00032292\n",
      "Iteration 23, loss = 0.00031316\n",
      "Iteration 24, loss = 0.00029749\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07140024\n",
      "Iteration 2, loss = 0.00143556\n",
      "Iteration 3, loss = 0.00127951\n",
      "Iteration 4, loss = 0.00107872\n",
      "Iteration 5, loss = 0.00081737\n",
      "Iteration 6, loss = 0.00048309\n",
      "Iteration 7, loss = 0.00028437\n",
      "Iteration 8, loss = 0.00025010\n",
      "Iteration 9, loss = 0.00022578\n",
      "Iteration 10, loss = 0.00020758\n",
      "Iteration 11, loss = 0.00019330\n",
      "Iteration 12, loss = 0.00018169\n",
      "Iteration 13, loss = 0.00017187\n",
      "Iteration 14, loss = 0.00016353\n",
      "Iteration 15, loss = 0.00015631\n",
      "Iteration 16, loss = 0.00014992\n",
      "Iteration 17, loss = 0.00014426\n",
      "Iteration 18, loss = 0.00013919\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07144846\n",
      "Iteration 2, loss = 0.00130216\n",
      "Iteration 3, loss = 0.00113632\n",
      "Iteration 4, loss = 0.00094817\n",
      "Iteration 5, loss = 0.00073121\n",
      "Iteration 6, loss = 0.00048301\n",
      "Iteration 7, loss = 0.00029456\n",
      "Iteration 8, loss = 0.00025072\n",
      "Iteration 9, loss = 0.00022572\n",
      "Iteration 10, loss = 0.00020684\n",
      "Iteration 11, loss = 0.00019256\n",
      "Iteration 12, loss = 0.00018095\n",
      "Iteration 13, loss = 0.00017120\n",
      "Iteration 14, loss = 0.00016290\n",
      "Iteration 15, loss = 0.00015563\n",
      "Iteration 16, loss = 0.00014927\n",
      "Iteration 17, loss = 0.00014361\n",
      "Iteration 18, loss = 0.00013853\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07630122\n",
      "Iteration 2, loss = 0.00773853\n",
      "Iteration 3, loss = 0.00496006\n",
      "Iteration 4, loss = 0.00234320\n",
      "Iteration 5, loss = 0.00120971\n",
      "Iteration 6, loss = 0.00070711\n",
      "Iteration 7, loss = 0.00046802\n",
      "Iteration 8, loss = 0.00036574\n",
      "Iteration 9, loss = 0.00031216\n",
      "Iteration 10, loss = 0.00027852\n",
      "Iteration 11, loss = 0.00025390\n",
      "Iteration 12, loss = 0.00023528\n",
      "Iteration 13, loss = 0.00022025\n",
      "Iteration 14, loss = 0.00020794\n",
      "Iteration 15, loss = 0.00019729\n",
      "Iteration 16, loss = 0.00018838\n",
      "Iteration 17, loss = 0.00018050\n",
      "Iteration 18, loss = 0.00017345\n",
      "Iteration 19, loss = 0.00016713\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07568634\n",
      "Iteration 2, loss = 0.00657279\n",
      "Iteration 3, loss = 0.00383612\n",
      "Iteration 4, loss = 0.00202014\n",
      "Iteration 5, loss = 0.00132510\n",
      "Iteration 6, loss = 0.00083273\n",
      "Iteration 7, loss = 0.00053436\n",
      "Iteration 8, loss = 0.00044140\n",
      "Iteration 9, loss = 0.00036864\n",
      "Iteration 10, loss = 0.00032064\n",
      "Iteration 11, loss = 0.00028645\n",
      "Iteration 12, loss = 0.00026344\n",
      "Iteration 13, loss = 0.00024477\n",
      "Iteration 14, loss = 0.00022883\n",
      "Iteration 15, loss = 0.00021459\n",
      "Iteration 16, loss = 0.00020216\n",
      "Iteration 17, loss = 0.00019242\n",
      "Iteration 18, loss = 0.00018484\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07670660\n",
      "Iteration 2, loss = 0.00695749\n",
      "Iteration 3, loss = 0.00258015\n",
      "Iteration 4, loss = 0.00125064\n",
      "Iteration 5, loss = 0.00073451\n",
      "Iteration 6, loss = 0.00054109\n",
      "Iteration 7, loss = 0.00042944\n",
      "Iteration 8, loss = 0.00035835\n",
      "Iteration 9, loss = 0.00031256\n",
      "Iteration 10, loss = 0.00027804\n",
      "Iteration 11, loss = 0.00025141\n",
      "Iteration 12, loss = 0.00023305\n",
      "Iteration 13, loss = 0.00021724\n",
      "Iteration 14, loss = 0.00020313\n",
      "Iteration 15, loss = 0.00019157\n",
      "Iteration 16, loss = 0.00018230\n",
      "Iteration 17, loss = 0.00017459\n",
      "Iteration 18, loss = 0.00016696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07650326\n",
      "Iteration 2, loss = 0.00672041\n",
      "Iteration 3, loss = 0.00422797\n",
      "Iteration 4, loss = 0.00210196\n",
      "Iteration 5, loss = 0.00100135\n",
      "Iteration 6, loss = 0.00062320\n",
      "Iteration 7, loss = 0.00044158\n",
      "Iteration 8, loss = 0.00036291\n",
      "Iteration 9, loss = 0.00030852\n",
      "Iteration 10, loss = 0.00027595\n",
      "Iteration 11, loss = 0.00024963\n",
      "Iteration 12, loss = 0.00023051\n",
      "Iteration 13, loss = 0.00021494\n",
      "Iteration 14, loss = 0.00020197\n",
      "Iteration 15, loss = 0.00019121\n",
      "Iteration 16, loss = 0.00018217\n",
      "Iteration 17, loss = 0.00017423\n",
      "Iteration 18, loss = 0.00016728\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07320489\n",
      "Iteration 2, loss = 0.00436983\n",
      "Iteration 3, loss = 0.00359305\n",
      "Iteration 4, loss = 0.00263816\n",
      "Iteration 5, loss = 0.00174747\n",
      "Iteration 6, loss = 0.00081703\n",
      "Iteration 7, loss = 0.00048043\n",
      "Iteration 8, loss = 0.00036729\n",
      "Iteration 9, loss = 0.00031240\n",
      "Iteration 10, loss = 0.00027254\n",
      "Iteration 11, loss = 0.00024611\n",
      "Iteration 12, loss = 0.00022632\n",
      "Iteration 13, loss = 0.00021107\n",
      "Iteration 14, loss = 0.00019863\n",
      "Iteration 15, loss = 0.00018827\n",
      "Iteration 16, loss = 0.00017938\n",
      "Iteration 17, loss = 0.00017174\n",
      "Iteration 18, loss = 0.00016499\n",
      "Iteration 19, loss = 0.00015898\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07304161\n",
      "Iteration 2, loss = 0.00394967\n",
      "Iteration 3, loss = 0.00329945\n",
      "Iteration 4, loss = 0.00245602\n",
      "Iteration 5, loss = 0.00162013\n",
      "Iteration 6, loss = 0.00085329\n",
      "Iteration 7, loss = 0.00057403\n",
      "Iteration 8, loss = 0.00044389\n",
      "Iteration 9, loss = 0.00036884\n",
      "Iteration 10, loss = 0.00033311\n",
      "Iteration 11, loss = 0.00031586\n",
      "Iteration 12, loss = 0.00027015\n",
      "Iteration 13, loss = 0.00025314\n",
      "Iteration 14, loss = 0.00023178\n",
      "Iteration 15, loss = 0.00022886\n",
      "Iteration 16, loss = 0.00020622\n",
      "Iteration 17, loss = 0.00019961\n",
      "Iteration 18, loss = 0.00018632\n",
      "Iteration 19, loss = 0.00018288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07660288\n",
      "Iteration 2, loss = 0.00748708\n",
      "Iteration 3, loss = 0.00470223\n",
      "Iteration 4, loss = 0.00262848\n",
      "Iteration 5, loss = 0.00121794\n",
      "Iteration 6, loss = 0.00061330\n",
      "Iteration 7, loss = 0.00044354\n",
      "Iteration 8, loss = 0.00036271\n",
      "Iteration 9, loss = 0.00031262\n",
      "Iteration 10, loss = 0.00027901\n",
      "Iteration 11, loss = 0.00025482\n",
      "Iteration 12, loss = 0.00023645\n",
      "Iteration 13, loss = 0.00022056\n",
      "Iteration 14, loss = 0.00020806\n",
      "Iteration 15, loss = 0.00019766\n",
      "Iteration 16, loss = 0.00018866\n",
      "Iteration 17, loss = 0.00018081\n",
      "Iteration 18, loss = 0.00017393\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07718529\n",
      "Iteration 2, loss = 0.00898251\n",
      "Iteration 3, loss = 0.00585401\n",
      "Iteration 4, loss = 0.00231311\n",
      "Iteration 5, loss = 0.00100701\n",
      "Iteration 6, loss = 0.00066179\n",
      "Iteration 7, loss = 0.00051939\n",
      "Iteration 8, loss = 0.00042739\n",
      "Iteration 9, loss = 0.00035442\n",
      "Iteration 10, loss = 0.00030890\n",
      "Iteration 11, loss = 0.00027278\n",
      "Iteration 12, loss = 0.00025621\n",
      "Iteration 13, loss = 0.00023899\n",
      "Iteration 14, loss = 0.00022007\n",
      "Iteration 15, loss = 0.00020762\n",
      "Iteration 16, loss = 0.00019827\n",
      "Iteration 17, loss = 0.00018875\n",
      "Iteration 18, loss = 0.00017881\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08851651\n",
      "Iteration 2, loss = 0.00548258\n",
      "Iteration 3, loss = 0.00334158\n",
      "Iteration 4, loss = 0.00213897\n",
      "Iteration 5, loss = 0.00144392\n",
      "Iteration 6, loss = 0.00137935\n",
      "Iteration 7, loss = 0.00100518\n",
      "Iteration 8, loss = 0.00082472\n",
      "Iteration 9, loss = 0.00074038\n",
      "Iteration 10, loss = 0.00071802\n",
      "Iteration 11, loss = 0.00088179\n",
      "Iteration 12, loss = 0.00080597\n",
      "Iteration 13, loss = 0.00065550\n",
      "Iteration 14, loss = 0.00069317\n",
      "Iteration 15, loss = 0.00054456\n",
      "Iteration 16, loss = 0.00075593\n",
      "Iteration 17, loss = 0.00072074\n",
      "Iteration 18, loss = 0.00052160\n",
      "Iteration 19, loss = 0.00054830\n",
      "Iteration 20, loss = 0.00052989\n",
      "Iteration 21, loss = 0.00052046\n",
      "Iteration 22, loss = 0.00044178\n",
      "Iteration 23, loss = 0.00060791\n",
      "Iteration 24, loss = 0.00044766\n",
      "Iteration 25, loss = 0.00054152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.08138537\n",
      "Iteration 2, loss = 0.01211077\n",
      "Iteration 3, loss = 0.00671715\n",
      "Iteration 4, loss = 0.00306671\n",
      "Iteration 5, loss = 0.00159923\n",
      "Iteration 6, loss = 0.00101390\n",
      "Iteration 7, loss = 0.00075401\n",
      "Iteration 8, loss = 0.00058231\n",
      "Iteration 9, loss = 0.00047755\n",
      "Iteration 10, loss = 0.00040218\n",
      "Iteration 11, loss = 0.00034642\n",
      "Iteration 12, loss = 0.00031839\n",
      "Iteration 13, loss = 0.00029142\n",
      "Iteration 14, loss = 0.00026612\n",
      "Iteration 15, loss = 0.00024947\n",
      "Iteration 16, loss = 0.00023623\n",
      "Iteration 17, loss = 0.00022315\n",
      "Iteration 18, loss = 0.00021111\n",
      "Iteration 19, loss = 0.00020321\n",
      "Iteration 20, loss = 0.00019471\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07090174\n",
      "Iteration 2, loss = 0.00137167\n",
      "Iteration 3, loss = 0.00125931\n",
      "Iteration 4, loss = 0.00116776\n",
      "Iteration 5, loss = 0.00086901\n",
      "Iteration 6, loss = 0.00068211\n",
      "Iteration 7, loss = 0.00053592\n",
      "Iteration 8, loss = 0.00048037\n",
      "Iteration 9, loss = 0.00034284\n",
      "Iteration 10, loss = 0.00033070\n",
      "Iteration 11, loss = 0.00029387\n",
      "Iteration 12, loss = 0.00027551\n",
      "Iteration 13, loss = 0.00023686\n",
      "Iteration 14, loss = 0.00021742\n",
      "Iteration 15, loss = 0.00020155\n",
      "Iteration 16, loss = 0.00019835\n",
      "Iteration 17, loss = 0.00018402\n",
      "Iteration 18, loss = 0.00017369\n",
      "Iteration 19, loss = 0.00016519\n",
      "Iteration 20, loss = 0.00016288\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.15713564\n",
      "Iteration 2, loss = 0.02136940\n",
      "Iteration 3, loss = 0.01052081\n",
      "Iteration 4, loss = 0.00560487\n",
      "Iteration 5, loss = 0.00338980\n",
      "Iteration 6, loss = 0.00230749\n",
      "Iteration 7, loss = 0.00186553\n",
      "Iteration 8, loss = 0.00143527\n",
      "Iteration 9, loss = 0.00121530\n",
      "Iteration 10, loss = 0.00108839\n",
      "Iteration 11, loss = 0.00088476\n",
      "Iteration 12, loss = 0.00079363\n",
      "Iteration 13, loss = 0.00084057\n",
      "Iteration 14, loss = 0.00067450\n",
      "Iteration 15, loss = 0.00081820\n",
      "Iteration 16, loss = 0.00061235\n",
      "Iteration 17, loss = 0.00055978\n",
      "Iteration 18, loss = 0.00058398\n",
      "Iteration 19, loss = 0.00057952\n",
      "Iteration 20, loss = 0.00070983\n",
      "Iteration 21, loss = 0.00048340\n",
      "Iteration 22, loss = 0.00041326\n",
      "Iteration 23, loss = 0.00037132\n",
      "Iteration 24, loss = 0.00046775\n",
      "Iteration 25, loss = 0.00038771\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.09711261\n",
      "Iteration 2, loss = 0.02193485\n",
      "Iteration 3, loss = 0.01048381\n",
      "Iteration 4, loss = 0.00432781\n",
      "Iteration 5, loss = 0.00229665\n",
      "Iteration 6, loss = 0.00153955\n",
      "Iteration 7, loss = 0.00116260\n",
      "Iteration 8, loss = 0.00096681\n",
      "Iteration 9, loss = 0.00078241\n",
      "Iteration 10, loss = 0.00068911\n",
      "Iteration 11, loss = 0.00058503\n",
      "Iteration 12, loss = 0.00053969\n",
      "Iteration 13, loss = 0.00054208\n",
      "Iteration 14, loss = 0.00045788\n",
      "Iteration 15, loss = 0.00046591\n",
      "Iteration 16, loss = 0.00040595\n",
      "Iteration 17, loss = 0.00036328\n",
      "Iteration 18, loss = 0.00035757\n",
      "Iteration 19, loss = 0.00036342\n",
      "Iteration 20, loss = 0.00040049\n",
      "Iteration 21, loss = 0.00031349\n",
      "Iteration 22, loss = 0.00028986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07334143\n",
      "Iteration 2, loss = 0.00548551\n",
      "Iteration 3, loss = 0.00380104\n",
      "Iteration 4, loss = 0.00188336\n",
      "Iteration 5, loss = 0.00097412\n",
      "Iteration 6, loss = 0.00064570\n",
      "Iteration 7, loss = 0.00050952\n",
      "Iteration 8, loss = 0.00043060\n",
      "Iteration 9, loss = 0.00035915\n",
      "Iteration 10, loss = 0.00032725\n",
      "Iteration 11, loss = 0.00028044\n",
      "Iteration 12, loss = 0.00025528\n",
      "Iteration 13, loss = 0.00023716\n",
      "Iteration 14, loss = 0.00021962\n",
      "Iteration 15, loss = 0.00020837\n",
      "Iteration 16, loss = 0.00019806\n",
      "Iteration 17, loss = 0.00018863\n",
      "Iteration 18, loss = 0.00017972\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07328323\n",
      "Iteration 2, loss = 0.00491848\n",
      "Iteration 3, loss = 0.00304449\n",
      "Iteration 4, loss = 0.00155277\n",
      "Iteration 5, loss = 0.00101950\n",
      "Iteration 6, loss = 0.00060410\n",
      "Iteration 7, loss = 0.00045463\n",
      "Iteration 8, loss = 0.00037241\n",
      "Iteration 9, loss = 0.00033472\n",
      "Iteration 10, loss = 0.00030173\n",
      "Iteration 11, loss = 0.00026140\n",
      "Iteration 12, loss = 0.00024112\n",
      "Iteration 13, loss = 0.00022146\n",
      "Iteration 14, loss = 0.00020972\n",
      "Iteration 15, loss = 0.00019406\n",
      "Iteration 16, loss = 0.00018720\n",
      "Iteration 17, loss = 0.00017683\n",
      "Iteration 18, loss = 0.00016862\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07217052\n",
      "Iteration 2, loss = 0.00200690\n",
      "Iteration 3, loss = 0.00159165\n",
      "Iteration 4, loss = 0.00113555\n",
      "Iteration 5, loss = 0.00064059\n",
      "Iteration 6, loss = 0.00038810\n",
      "Iteration 7, loss = 0.00029398\n",
      "Iteration 8, loss = 0.00025530\n",
      "Iteration 9, loss = 0.00023033\n",
      "Iteration 10, loss = 0.00021166\n",
      "Iteration 11, loss = 0.00019702\n",
      "Iteration 12, loss = 0.00018510\n",
      "Iteration 13, loss = 0.00017512\n",
      "Iteration 14, loss = 0.00016659\n",
      "Iteration 15, loss = 0.00015921\n",
      "Iteration 16, loss = 0.00015270\n",
      "Iteration 17, loss = 0.00014691\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10524185\n",
      "Iteration 2, loss = 0.01550472\n",
      "Iteration 3, loss = 0.00641803\n",
      "Iteration 4, loss = 0.00286436\n",
      "Iteration 5, loss = 0.00145920\n",
      "Iteration 6, loss = 0.00100641\n",
      "Iteration 7, loss = 0.00079847\n",
      "Iteration 8, loss = 0.00063627\n",
      "Iteration 9, loss = 0.00055103\n",
      "Iteration 10, loss = 0.00052162\n",
      "Iteration 11, loss = 0.00041180\n",
      "Iteration 12, loss = 0.00037368\n",
      "Iteration 13, loss = 0.00034216\n",
      "Iteration 14, loss = 0.00032166\n",
      "Iteration 15, loss = 0.00029558\n",
      "Iteration 16, loss = 0.00028487\n",
      "Iteration 17, loss = 0.00026750\n",
      "Iteration 18, loss = 0.00025511\n",
      "Iteration 19, loss = 0.00024455\n",
      "Iteration 20, loss = 0.00023580\n",
      "Iteration 21, loss = 0.00022854\n",
      "Iteration 22, loss = 0.00021973\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.09950834\n",
      "Iteration 2, loss = 0.00742956\n",
      "Iteration 3, loss = 0.00349232\n",
      "Iteration 4, loss = 0.00218657\n",
      "Iteration 5, loss = 0.00149014\n",
      "Iteration 6, loss = 0.00110927\n",
      "Iteration 7, loss = 0.00091419\n",
      "Iteration 8, loss = 0.00072918\n",
      "Iteration 9, loss = 0.00057664\n",
      "Iteration 10, loss = 0.00046658\n",
      "Iteration 11, loss = 0.00041305\n",
      "Iteration 12, loss = 0.00035218\n",
      "Iteration 13, loss = 0.00032516\n",
      "Iteration 14, loss = 0.00030069\n",
      "Iteration 15, loss = 0.00027811\n",
      "Iteration 16, loss = 0.00025812\n",
      "Iteration 17, loss = 0.00024542\n",
      "Iteration 18, loss = 0.00023206\n",
      "Iteration 19, loss = 0.00021999\n",
      "Iteration 20, loss = 0.00021063\n",
      "Iteration 21, loss = 0.00020214\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07331985\n",
      "Iteration 2, loss = 0.00325056\n",
      "Iteration 3, loss = 0.00251557\n",
      "Iteration 4, loss = 0.00156043\n",
      "Iteration 5, loss = 0.00076649\n",
      "Iteration 6, loss = 0.00047453\n",
      "Iteration 7, loss = 0.00034477\n",
      "Iteration 8, loss = 0.00028764\n",
      "Iteration 9, loss = 0.00025399\n",
      "Iteration 10, loss = 0.00023048\n",
      "Iteration 11, loss = 0.00021263\n",
      "Iteration 12, loss = 0.00019862\n",
      "Iteration 13, loss = 0.00018713\n",
      "Iteration 14, loss = 0.00017734\n",
      "Iteration 15, loss = 0.00016906\n",
      "Iteration 16, loss = 0.00016181\n",
      "Iteration 17, loss = 0.00015545\n",
      "Iteration 18, loss = 0.00014976\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07575717\n",
      "Iteration 2, loss = 0.00659942\n",
      "Iteration 3, loss = 0.00398314\n",
      "Iteration 4, loss = 0.00187482\n",
      "Iteration 5, loss = 0.00088415\n",
      "Iteration 6, loss = 0.00045686\n",
      "Iteration 7, loss = 0.00035641\n",
      "Iteration 8, loss = 0.00030470\n",
      "Iteration 9, loss = 0.00027033\n",
      "Iteration 10, loss = 0.00024654\n",
      "Iteration 11, loss = 0.00022752\n",
      "Iteration 12, loss = 0.00021301\n",
      "Iteration 13, loss = 0.00020092\n",
      "Iteration 14, loss = 0.00019053\n",
      "Iteration 15, loss = 0.00018172\n",
      "Iteration 16, loss = 0.00017400\n",
      "Iteration 17, loss = 0.00016721\n",
      "Iteration 18, loss = 0.00016111\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.12113642\n",
      "Iteration 2, loss = 0.02299461\n",
      "Iteration 3, loss = 0.00785300\n",
      "Iteration 4, loss = 0.00320921\n",
      "Iteration 5, loss = 0.00175386\n",
      "Iteration 6, loss = 0.00119122\n",
      "Iteration 7, loss = 0.00084011\n",
      "Iteration 8, loss = 0.00068243\n",
      "Iteration 9, loss = 0.00056999\n",
      "Iteration 10, loss = 0.00049224\n",
      "Iteration 11, loss = 0.00043127\n",
      "Iteration 12, loss = 0.00039869\n",
      "Iteration 13, loss = 0.00037029\n",
      "Iteration 14, loss = 0.00034493\n",
      "Iteration 15, loss = 0.00032530\n",
      "Iteration 16, loss = 0.00030935\n",
      "Iteration 17, loss = 0.00029518\n",
      "Iteration 18, loss = 0.00028188\n",
      "Iteration 19, loss = 0.00027146\n",
      "Iteration 20, loss = 0.00026097\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07327204\n",
      "Iteration 2, loss = 0.00308184\n",
      "Iteration 3, loss = 0.00164575\n",
      "Iteration 4, loss = 0.00098257\n",
      "Iteration 5, loss = 0.00058901\n",
      "Iteration 6, loss = 0.00038132\n",
      "Iteration 7, loss = 0.00031465\n",
      "Iteration 8, loss = 0.00027479\n",
      "Iteration 9, loss = 0.00024690\n",
      "Iteration 10, loss = 0.00022600\n",
      "Iteration 11, loss = 0.00020936\n",
      "Iteration 12, loss = 0.00019608\n",
      "Iteration 13, loss = 0.00018543\n",
      "Iteration 14, loss = 0.00017594\n",
      "Iteration 15, loss = 0.00016800\n",
      "Iteration 16, loss = 0.00016099\n",
      "Iteration 17, loss = 0.00015475\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.11942916\n",
      "Iteration 2, loss = 0.02003272\n",
      "Iteration 3, loss = 0.00825344\n",
      "Iteration 4, loss = 0.00371229\n",
      "Iteration 5, loss = 0.00197559\n",
      "Iteration 6, loss = 0.00127040\n",
      "Iteration 7, loss = 0.00100185\n",
      "Iteration 8, loss = 0.00087238\n",
      "Iteration 9, loss = 0.00068124\n",
      "Iteration 10, loss = 0.00056184\n",
      "Iteration 11, loss = 0.00051947\n",
      "Iteration 12, loss = 0.00044625\n",
      "Iteration 13, loss = 0.00039784\n",
      "Iteration 14, loss = 0.00037237\n",
      "Iteration 15, loss = 0.00035156\n",
      "Iteration 16, loss = 0.00032428\n",
      "Iteration 17, loss = 0.00031299\n",
      "Iteration 18, loss = 0.00029841\n",
      "Iteration 19, loss = 0.00028249\n",
      "Iteration 20, loss = 0.00027348\n",
      "Iteration 21, loss = 0.00026446\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08899244\n",
      "Iteration 2, loss = 0.01234099\n",
      "Iteration 3, loss = 0.00379632\n",
      "Iteration 4, loss = 0.00172449\n",
      "Iteration 5, loss = 0.00091049\n",
      "Iteration 6, loss = 0.00064368\n",
      "Iteration 7, loss = 0.00051876\n",
      "Iteration 8, loss = 0.00045913\n",
      "Iteration 9, loss = 0.00042755\n",
      "Iteration 10, loss = 0.00039122\n",
      "Iteration 11, loss = 0.00035609\n",
      "Iteration 12, loss = 0.00031636\n",
      "Iteration 13, loss = 0.00029600\n",
      "Iteration 14, loss = 0.00026028\n",
      "Iteration 15, loss = 0.00027006\n",
      "Iteration 16, loss = 0.00024541\n",
      "Iteration 17, loss = 0.00023443\n",
      "Iteration 18, loss = 0.00023138\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07142455\n",
      "Iteration 2, loss = 0.00144450\n",
      "Iteration 3, loss = 0.00120098\n",
      "Iteration 4, loss = 0.00086993\n",
      "Iteration 5, loss = 0.00043526\n",
      "Iteration 6, loss = 0.00028816\n",
      "Iteration 7, loss = 0.00025547\n",
      "Iteration 8, loss = 0.00023150\n",
      "Iteration 9, loss = 0.00021301\n",
      "Iteration 10, loss = 0.00019823\n",
      "Iteration 11, loss = 0.00018609\n",
      "Iteration 12, loss = 0.00017589\n",
      "Iteration 13, loss = 0.00016718\n",
      "Iteration 14, loss = 0.00015958\n",
      "Iteration 15, loss = 0.00015291\n",
      "Iteration 16, loss = 0.00014697\n",
      "Iteration 17, loss = 0.00014165\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07119881\n",
      "Iteration 2, loss = 0.00195945\n",
      "Iteration 3, loss = 0.00129299\n",
      "Iteration 4, loss = 0.00053956\n",
      "Iteration 5, loss = 0.00033329\n",
      "Iteration 6, loss = 0.00028791\n",
      "Iteration 7, loss = 0.00025589\n",
      "Iteration 8, loss = 0.00023212\n",
      "Iteration 9, loss = 0.00021379\n",
      "Iteration 10, loss = 0.00019901\n",
      "Iteration 11, loss = 0.00018690\n",
      "Iteration 12, loss = 0.00017665\n",
      "Iteration 13, loss = 0.00016791\n",
      "Iteration 14, loss = 0.00016026\n",
      "Iteration 15, loss = 0.00015357\n",
      "Iteration 16, loss = 0.00014758\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07431234\n",
      "Iteration 2, loss = 0.00443981\n",
      "Iteration 3, loss = 0.00193803\n",
      "Iteration 4, loss = 0.00092585\n",
      "Iteration 5, loss = 0.00045540\n",
      "Iteration 6, loss = 0.00035212\n",
      "Iteration 7, loss = 0.00029855\n",
      "Iteration 8, loss = 0.00026379\n",
      "Iteration 9, loss = 0.00023889\n",
      "Iteration 10, loss = 0.00021975\n",
      "Iteration 11, loss = 0.00020463\n",
      "Iteration 12, loss = 0.00019228\n",
      "Iteration 13, loss = 0.00018186\n",
      "Iteration 14, loss = 0.00017304\n",
      "Iteration 15, loss = 0.00016529\n",
      "Iteration 16, loss = 0.00015849\n",
      "Iteration 17, loss = 0.00015249\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.11262997\n",
      "Iteration 2, loss = 0.02192296\n",
      "Iteration 3, loss = 0.00826317\n",
      "Iteration 4, loss = 0.00341026\n",
      "Iteration 5, loss = 0.00177561\n",
      "Iteration 6, loss = 0.00118943\n",
      "Iteration 7, loss = 0.00085597\n",
      "Iteration 8, loss = 0.00065075\n",
      "Iteration 9, loss = 0.00055815\n",
      "Iteration 10, loss = 0.00049255\n",
      "Iteration 11, loss = 0.00044157\n",
      "Iteration 12, loss = 0.00040249\n",
      "Iteration 13, loss = 0.00037262\n",
      "Iteration 14, loss = 0.00034877\n",
      "Iteration 15, loss = 0.00032966\n",
      "Iteration 16, loss = 0.00031060\n",
      "Iteration 17, loss = 0.00029640\n",
      "Iteration 18, loss = 0.00028333\n",
      "Iteration 19, loss = 0.00027129\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08816506\n",
      "Iteration 2, loss = 0.01385369\n",
      "Iteration 3, loss = 0.00577889\n",
      "Iteration 4, loss = 0.00258658\n",
      "Iteration 5, loss = 0.00125760\n",
      "Iteration 6, loss = 0.00075707\n",
      "Iteration 7, loss = 0.00058489\n",
      "Iteration 8, loss = 0.00046419\n",
      "Iteration 9, loss = 0.00039871\n",
      "Iteration 10, loss = 0.00035061\n",
      "Iteration 11, loss = 0.00031729\n",
      "Iteration 12, loss = 0.00028774\n",
      "Iteration 13, loss = 0.00026624\n",
      "Iteration 14, loss = 0.00024923\n",
      "Iteration 15, loss = 0.00023539\n",
      "Iteration 16, loss = 0.00022652\n",
      "Iteration 17, loss = 0.00021245\n",
      "Iteration 18, loss = 0.00020311\n",
      "Iteration 19, loss = 0.00019593\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.12149002\n",
      "Iteration 2, loss = 0.02076687\n",
      "Iteration 3, loss = 0.00578381\n",
      "Iteration 4, loss = 0.00289957\n",
      "Iteration 5, loss = 0.00165013\n",
      "Iteration 6, loss = 0.00115938\n",
      "Iteration 7, loss = 0.00084850\n",
      "Iteration 8, loss = 0.00069123\n",
      "Iteration 9, loss = 0.00057136\n",
      "Iteration 10, loss = 0.00048521\n",
      "Iteration 11, loss = 0.00043177\n",
      "Iteration 12, loss = 0.00038632\n",
      "Iteration 13, loss = 0.00035670\n",
      "Iteration 14, loss = 0.00032937\n",
      "Iteration 15, loss = 0.00030840\n",
      "Iteration 16, loss = 0.00029259\n",
      "Iteration 17, loss = 0.00027591\n",
      "Iteration 18, loss = 0.00026303\n",
      "Iteration 19, loss = 0.00025244\n",
      "Iteration 20, loss = 0.00024156\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07329368\n",
      "Iteration 2, loss = 0.00415746\n",
      "Iteration 3, loss = 0.00302875\n",
      "Iteration 4, loss = 0.00181515\n",
      "Iteration 5, loss = 0.00094003\n",
      "Iteration 6, loss = 0.00051116\n",
      "Iteration 7, loss = 0.00036855\n",
      "Iteration 8, loss = 0.00030465\n",
      "Iteration 9, loss = 0.00026661\n",
      "Iteration 10, loss = 0.00024043\n",
      "Iteration 11, loss = 0.00022117\n",
      "Iteration 12, loss = 0.00020573\n",
      "Iteration 13, loss = 0.00019338\n",
      "Iteration 14, loss = 0.00018305\n",
      "Iteration 15, loss = 0.00017435\n",
      "Iteration 16, loss = 0.00016665\n",
      "Iteration 17, loss = 0.00015998\n",
      "Iteration 18, loss = 0.00015403\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07125155\n",
      "Iteration 2, loss = 0.00109027\n",
      "Iteration 3, loss = 0.00089622\n",
      "Iteration 4, loss = 0.00068102\n",
      "Iteration 5, loss = 0.00046617\n",
      "Iteration 6, loss = 0.00032160\n",
      "Iteration 7, loss = 0.00026627\n",
      "Iteration 8, loss = 0.00023679\n",
      "Iteration 9, loss = 0.00021584\n",
      "Iteration 10, loss = 0.00019982\n",
      "Iteration 11, loss = 0.00018711\n",
      "Iteration 12, loss = 0.00017625\n",
      "Iteration 13, loss = 0.00016722\n",
      "Iteration 14, loss = 0.00015935\n",
      "Iteration 15, loss = 0.00015254\n",
      "Iteration 16, loss = 0.00014643\n",
      "Iteration 17, loss = 0.00014100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.13595028\n",
      "Iteration 2, loss = 0.01006416\n",
      "Iteration 3, loss = 0.00313112\n",
      "Iteration 4, loss = 0.00170608\n",
      "Iteration 5, loss = 0.00087712\n",
      "Iteration 6, loss = 0.00064708\n",
      "Iteration 7, loss = 0.00052514\n",
      "Iteration 8, loss = 0.00045268\n",
      "Iteration 9, loss = 0.00039936\n",
      "Iteration 10, loss = 0.00036314\n",
      "Iteration 11, loss = 0.00033457\n",
      "Iteration 12, loss = 0.00031248\n",
      "Iteration 13, loss = 0.00029407\n",
      "Iteration 14, loss = 0.00027874\n",
      "Iteration 15, loss = 0.00026581\n",
      "Iteration 16, loss = 0.00025456\n",
      "Iteration 17, loss = 0.00024473\n",
      "Iteration 18, loss = 0.00023600\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07147716\n",
      "Iteration 2, loss = 0.00141858\n",
      "Iteration 3, loss = 0.00127074\n",
      "Iteration 4, loss = 0.00110016\n",
      "Iteration 5, loss = 0.00086222\n",
      "Iteration 6, loss = 0.00055120\n",
      "Iteration 7, loss = 0.00030238\n",
      "Iteration 8, loss = 0.00025345\n",
      "Iteration 9, loss = 0.00022749\n",
      "Iteration 10, loss = 0.00020858\n",
      "Iteration 11, loss = 0.00019408\n",
      "Iteration 12, loss = 0.00018199\n",
      "Iteration 13, loss = 0.00017226\n",
      "Iteration 14, loss = 0.00016362\n",
      "Iteration 15, loss = 0.00015634\n",
      "Iteration 16, loss = 0.00014993\n",
      "Iteration 17, loss = 0.00014429\n",
      "Iteration 18, loss = 0.00013910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07405995\n",
      "Iteration 2, loss = 0.00469824\n",
      "Iteration 3, loss = 0.00307209\n",
      "Iteration 4, loss = 0.00164229\n",
      "Iteration 5, loss = 0.00073560\n",
      "Iteration 6, loss = 0.00053108\n",
      "Iteration 7, loss = 0.00044526\n",
      "Iteration 8, loss = 0.00036433\n",
      "Iteration 9, loss = 0.00032696\n",
      "Iteration 10, loss = 0.00027777\n",
      "Iteration 11, loss = 0.00025094\n",
      "Iteration 12, loss = 0.00022994\n",
      "Iteration 13, loss = 0.00021673\n",
      "Iteration 14, loss = 0.00020054\n",
      "Iteration 15, loss = 0.00018951\n",
      "Iteration 16, loss = 0.00017979\n",
      "Iteration 17, loss = 0.00017119\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.11367810\n",
      "Iteration 2, loss = 0.01066813\n",
      "Iteration 3, loss = 0.00416599\n",
      "Iteration 4, loss = 0.00224304\n",
      "Iteration 5, loss = 0.00146820\n",
      "Iteration 6, loss = 0.00103971\n",
      "Iteration 7, loss = 0.00079177\n",
      "Iteration 8, loss = 0.00060931\n",
      "Iteration 9, loss = 0.00052234\n",
      "Iteration 10, loss = 0.00045111\n",
      "Iteration 11, loss = 0.00039951\n",
      "Iteration 12, loss = 0.00035452\n",
      "Iteration 13, loss = 0.00032727\n",
      "Iteration 14, loss = 0.00029970\n",
      "Iteration 15, loss = 0.00028096\n",
      "Iteration 16, loss = 0.00025913\n",
      "Iteration 17, loss = 0.00024505\n",
      "Iteration 18, loss = 0.00023275\n",
      "Iteration 19, loss = 0.00022084\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07329308\n",
      "Iteration 2, loss = 0.00421415\n",
      "Iteration 3, loss = 0.00201953\n",
      "Iteration 4, loss = 0.00088642\n",
      "Iteration 5, loss = 0.00056908\n",
      "Iteration 6, loss = 0.00039468\n",
      "Iteration 7, loss = 0.00031394\n",
      "Iteration 8, loss = 0.00027142\n",
      "Iteration 9, loss = 0.00024306\n",
      "Iteration 10, loss = 0.00022251\n",
      "Iteration 11, loss = 0.00020655\n",
      "Iteration 12, loss = 0.00019371\n",
      "Iteration 13, loss = 0.00018309\n",
      "Iteration 14, loss = 0.00017398\n",
      "Iteration 15, loss = 0.00016614\n",
      "Iteration 16, loss = 0.00015921\n",
      "Iteration 17, loss = 0.00015307\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07628424\n",
      "Iteration 2, loss = 0.00609464\n",
      "Iteration 3, loss = 0.00397671\n",
      "Iteration 4, loss = 0.00223600\n",
      "Iteration 5, loss = 0.00102668\n",
      "Iteration 6, loss = 0.00072578\n",
      "Iteration 7, loss = 0.00054768\n",
      "Iteration 8, loss = 0.00044919\n",
      "Iteration 9, loss = 0.00036495\n",
      "Iteration 10, loss = 0.00033200\n",
      "Iteration 11, loss = 0.00029956\n",
      "Iteration 12, loss = 0.00026728\n",
      "Iteration 13, loss = 0.00024217\n",
      "Iteration 14, loss = 0.00023480\n",
      "Iteration 15, loss = 0.00021386\n",
      "Iteration 16, loss = 0.00020155\n",
      "Iteration 17, loss = 0.00019149\n",
      "Iteration 18, loss = 0.00018392\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07722676\n",
      "Iteration 2, loss = 0.00608093\n",
      "Iteration 3, loss = 0.00408702\n",
      "Iteration 4, loss = 0.00236219\n",
      "Iteration 5, loss = 0.00120608\n",
      "Iteration 6, loss = 0.00064680\n",
      "Iteration 7, loss = 0.00044407\n",
      "Iteration 8, loss = 0.00035159\n",
      "Iteration 9, loss = 0.00030626\n",
      "Iteration 10, loss = 0.00026849\n",
      "Iteration 11, loss = 0.00024577\n",
      "Iteration 12, loss = 0.00022771\n",
      "Iteration 13, loss = 0.00021374\n",
      "Iteration 14, loss = 0.00020096\n",
      "Iteration 15, loss = 0.00019099\n",
      "Iteration 16, loss = 0.00018204\n",
      "Iteration 17, loss = 0.00017407\n",
      "Iteration 18, loss = 0.00016714\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10099900\n",
      "Iteration 2, loss = 0.01844270\n",
      "Iteration 3, loss = 0.00981259\n",
      "Iteration 4, loss = 0.00531931\n",
      "Iteration 5, loss = 0.00324553\n",
      "Iteration 6, loss = 0.00287019\n",
      "Iteration 7, loss = 0.00226279\n",
      "Iteration 8, loss = 0.00180997\n",
      "Iteration 9, loss = 0.00165676\n",
      "Iteration 10, loss = 0.00161613\n",
      "Iteration 11, loss = 0.00142061\n",
      "Iteration 12, loss = 0.00121698\n",
      "Iteration 13, loss = 0.00109527\n",
      "Iteration 14, loss = 0.00094217\n",
      "Iteration 15, loss = 0.00080650\n",
      "Iteration 16, loss = 0.00089411\n",
      "Iteration 17, loss = 0.00074202\n",
      "Iteration 18, loss = 0.00078957\n",
      "Iteration 19, loss = 0.00072273\n",
      "Iteration 20, loss = 0.00066111\n",
      "Iteration 21, loss = 0.00056039\n",
      "Iteration 22, loss = 0.00056335\n",
      "Iteration 23, loss = 0.00064468\n",
      "Iteration 24, loss = 0.00083577\n",
      "Iteration 25, loss = 0.00078116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.12673528\n",
      "Iteration 2, loss = 0.02371582\n",
      "Iteration 3, loss = 0.01224742\n",
      "Iteration 4, loss = 0.00660736\n",
      "Iteration 5, loss = 0.00366467\n",
      "Iteration 6, loss = 0.00270092\n",
      "Iteration 7, loss = 0.00234690\n",
      "Iteration 8, loss = 0.00211080\n",
      "Iteration 9, loss = 0.00142585\n",
      "Iteration 10, loss = 0.00184013\n",
      "Iteration 11, loss = 0.00120782\n",
      "Iteration 12, loss = 0.00103173\n",
      "Iteration 13, loss = 0.00088789\n",
      "Iteration 14, loss = 0.00076540\n",
      "Iteration 15, loss = 0.00060210\n",
      "Iteration 16, loss = 0.00065061\n",
      "Iteration 17, loss = 0.00074783\n",
      "Iteration 18, loss = 0.00071078\n",
      "Iteration 19, loss = 0.00051797\n",
      "Iteration 20, loss = 0.00059128\n",
      "Iteration 21, loss = 0.00047860\n",
      "Iteration 22, loss = 0.00053501\n",
      "Iteration 23, loss = 0.00062918\n",
      "Iteration 24, loss = 0.00119690\n",
      "Iteration 25, loss = 0.00074416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07398774\n",
      "Iteration 2, loss = 0.00452175\n",
      "Iteration 3, loss = 0.00247169\n",
      "Iteration 4, loss = 0.00149165\n",
      "Iteration 5, loss = 0.00108675\n",
      "Iteration 6, loss = 0.00072295\n",
      "Iteration 7, loss = 0.00054639\n",
      "Iteration 8, loss = 0.00046421\n",
      "Iteration 9, loss = 0.00040213\n",
      "Iteration 10, loss = 0.00035707\n",
      "Iteration 11, loss = 0.00034132\n",
      "Iteration 12, loss = 0.00027789\n",
      "Iteration 13, loss = 0.00026458\n",
      "Iteration 14, loss = 0.00023836\n",
      "Iteration 15, loss = 0.00022575\n",
      "Iteration 16, loss = 0.00020699\n",
      "Iteration 17, loss = 0.00019461\n",
      "Iteration 18, loss = 0.00018921\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.09395459\n",
      "Iteration 2, loss = 0.01441759\n",
      "Iteration 3, loss = 0.00873307\n",
      "Iteration 4, loss = 0.00576530\n",
      "Iteration 5, loss = 0.00392663\n",
      "Iteration 6, loss = 0.00281241\n",
      "Iteration 7, loss = 0.00248422\n",
      "Iteration 8, loss = 0.00181564\n",
      "Iteration 9, loss = 0.00141497\n",
      "Iteration 10, loss = 0.00121613\n",
      "Iteration 11, loss = 0.00117860\n",
      "Iteration 12, loss = 0.00095655\n",
      "Iteration 13, loss = 0.00083148\n",
      "Iteration 14, loss = 0.00074789\n",
      "Iteration 15, loss = 0.00062627\n",
      "Iteration 16, loss = 0.00056865\n",
      "Iteration 17, loss = 0.00051334\n",
      "Iteration 18, loss = 0.00053498\n",
      "Iteration 19, loss = 0.00044016\n",
      "Iteration 20, loss = 0.00039706\n",
      "Iteration 21, loss = 0.00037442\n",
      "Iteration 22, loss = 0.00034813\n",
      "Iteration 23, loss = 0.00033744\n",
      "Iteration 24, loss = 0.00030426\n",
      "Iteration 25, loss = 0.00027804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07188325\n",
      "Iteration 2, loss = 0.00417383\n",
      "Iteration 3, loss = 0.00206470\n",
      "Iteration 4, loss = 0.00064707\n",
      "Iteration 5, loss = 0.00038440\n",
      "Iteration 6, loss = 0.00031733\n",
      "Iteration 7, loss = 0.00027570\n",
      "Iteration 8, loss = 0.00024590\n",
      "Iteration 9, loss = 0.00022400\n",
      "Iteration 10, loss = 0.00020698\n",
      "Iteration 11, loss = 0.00019325\n",
      "Iteration 12, loss = 0.00018196\n",
      "Iteration 13, loss = 0.00017241\n",
      "Iteration 14, loss = 0.00016416\n",
      "Iteration 15, loss = 0.00015700\n",
      "Iteration 16, loss = 0.00015064\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.15805250\n",
      "Iteration 2, loss = 0.03620073\n",
      "Iteration 3, loss = 0.01508203\n",
      "Iteration 4, loss = 0.00803685\n",
      "Iteration 5, loss = 0.00487326\n",
      "Iteration 6, loss = 0.00312931\n",
      "Iteration 7, loss = 0.00204960\n",
      "Iteration 8, loss = 0.00145861\n",
      "Iteration 9, loss = 0.00113354\n",
      "Iteration 10, loss = 0.00089670\n",
      "Iteration 11, loss = 0.00080354\n",
      "Iteration 12, loss = 0.00085010\n",
      "Iteration 13, loss = 0.00115957\n",
      "Iteration 14, loss = 0.00051710\n",
      "Iteration 15, loss = 0.00045624\n",
      "Iteration 16, loss = 0.00042618\n",
      "Iteration 17, loss = 0.00039899\n",
      "Iteration 18, loss = 0.00037920\n",
      "Iteration 19, loss = 0.00036078\n",
      "Iteration 20, loss = 0.00034438\n",
      "Iteration 21, loss = 0.00033240\n",
      "Iteration 22, loss = 0.00031940\n",
      "Iteration 23, loss = 0.00030813\n",
      "Iteration 24, loss = 0.00029904\n",
      "Iteration 25, loss = 0.00029059\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.21715561\n",
      "Iteration 2, loss = 0.05137491\n",
      "Iteration 3, loss = 0.02621026\n",
      "Iteration 4, loss = 0.01725791\n",
      "Iteration 5, loss = 0.01147415\n",
      "Iteration 6, loss = 0.00787614\n",
      "Iteration 7, loss = 0.00560346\n",
      "Iteration 8, loss = 0.00443159\n",
      "Iteration 9, loss = 0.00317492\n",
      "Iteration 10, loss = 0.00337768\n",
      "Iteration 11, loss = 0.00504788\n",
      "Iteration 12, loss = 0.00231851\n",
      "Iteration 13, loss = 0.00251974\n",
      "Iteration 14, loss = 0.00206025\n",
      "Iteration 15, loss = 0.00117654\n",
      "Iteration 16, loss = 0.00101196\n",
      "Iteration 17, loss = 0.00101057\n",
      "Iteration 18, loss = 0.00133385\n",
      "Iteration 19, loss = 0.00118547\n",
      "Iteration 20, loss = 0.00097789\n",
      "Iteration 21, loss = 0.00095227\n",
      "Iteration 22, loss = 0.00070123\n",
      "Iteration 23, loss = 0.00115449\n",
      "Iteration 24, loss = 0.00084167\n",
      "Iteration 25, loss = 0.00124483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07891549\n",
      "Iteration 2, loss = 0.00791058\n",
      "Iteration 3, loss = 0.00369762\n",
      "Iteration 4, loss = 0.00245571\n",
      "Iteration 5, loss = 0.00138663\n",
      "Iteration 6, loss = 0.00090068\n",
      "Iteration 7, loss = 0.00048160\n",
      "Iteration 8, loss = 0.00038672\n",
      "Iteration 9, loss = 0.00033138\n",
      "Iteration 10, loss = 0.00029223\n",
      "Iteration 11, loss = 0.00026543\n",
      "Iteration 12, loss = 0.00024418\n",
      "Iteration 13, loss = 0.00022825\n",
      "Iteration 14, loss = 0.00021490\n",
      "Iteration 15, loss = 0.00020382\n",
      "Iteration 16, loss = 0.00019424\n",
      "Iteration 17, loss = 0.00018599\n",
      "Iteration 18, loss = 0.00017858\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.10632144\n",
      "Iteration 2, loss = 0.01646394\n",
      "Iteration 3, loss = 0.00688949\n",
      "Iteration 4, loss = 0.00393294\n",
      "Iteration 5, loss = 0.00245563\n",
      "Iteration 6, loss = 0.00166158\n",
      "Iteration 7, loss = 0.00129278\n",
      "Iteration 8, loss = 0.00094730\n",
      "Iteration 9, loss = 0.00073858\n",
      "Iteration 10, loss = 0.00075123\n",
      "Iteration 11, loss = 0.00054323\n",
      "Iteration 12, loss = 0.00055332\n",
      "Iteration 13, loss = 0.00045805\n",
      "Iteration 14, loss = 0.00042298\n",
      "Iteration 15, loss = 0.00037893\n",
      "Iteration 16, loss = 0.00034787\n",
      "Iteration 17, loss = 0.00033821\n",
      "Iteration 18, loss = 0.00030438\n",
      "Iteration 19, loss = 0.00028357\n",
      "Iteration 20, loss = 0.00027240\n",
      "Iteration 21, loss = 0.00026725\n",
      "Iteration 22, loss = 0.00025054\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.09400669\n",
      "Iteration 2, loss = 0.01760852\n",
      "Iteration 3, loss = 0.00913572\n",
      "Iteration 4, loss = 0.00399554\n",
      "Iteration 5, loss = 0.00194583\n",
      "Iteration 6, loss = 0.00130452\n",
      "Iteration 7, loss = 0.00092574\n",
      "Iteration 8, loss = 0.00075112\n",
      "Iteration 9, loss = 0.00059704\n",
      "Iteration 10, loss = 0.00049729\n",
      "Iteration 11, loss = 0.00043809\n",
      "Iteration 12, loss = 0.00038854\n",
      "Iteration 13, loss = 0.00035229\n",
      "Iteration 14, loss = 0.00032560\n",
      "Iteration 15, loss = 0.00030583\n",
      "Iteration 16, loss = 0.00028465\n",
      "Iteration 17, loss = 0.00026955\n",
      "Iteration 18, loss = 0.00025745\n",
      "Iteration 19, loss = 0.00024428\n",
      "Iteration 20, loss = 0.00023426\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07222136\n",
      "Iteration 2, loss = 0.00239329\n",
      "Iteration 3, loss = 0.00189061\n",
      "Iteration 4, loss = 0.00130985\n",
      "Iteration 5, loss = 0.00084953\n",
      "Iteration 6, loss = 0.00056869\n",
      "Iteration 7, loss = 0.00039030\n",
      "Iteration 8, loss = 0.00031008\n",
      "Iteration 9, loss = 0.00026975\n",
      "Iteration 10, loss = 0.00024200\n",
      "Iteration 11, loss = 0.00022150\n",
      "Iteration 12, loss = 0.00020457\n",
      "Iteration 13, loss = 0.00019215\n",
      "Iteration 14, loss = 0.00018073\n",
      "Iteration 15, loss = 0.00017223\n",
      "Iteration 16, loss = 0.00016364\n",
      "Iteration 17, loss = 0.00015701\n",
      "Iteration 18, loss = 0.00015114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08224776\n",
      "Iteration 2, loss = 0.01195619\n",
      "Iteration 3, loss = 0.00608114\n",
      "Iteration 4, loss = 0.00274664\n",
      "Iteration 5, loss = 0.00118822\n",
      "Iteration 6, loss = 0.00069097\n",
      "Iteration 7, loss = 0.00049926\n",
      "Iteration 8, loss = 0.00040487\n",
      "Iteration 9, loss = 0.00034734\n",
      "Iteration 10, loss = 0.00030949\n",
      "Iteration 11, loss = 0.00028196\n",
      "Iteration 12, loss = 0.00026008\n",
      "Iteration 13, loss = 0.00024250\n",
      "Iteration 14, loss = 0.00022851\n",
      "Iteration 15, loss = 0.00021660\n",
      "Iteration 16, loss = 0.00020632\n",
      "Iteration 17, loss = 0.00019742\n",
      "Iteration 18, loss = 0.00018959\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07066007\n",
      "Iteration 2, loss = 0.00129194\n",
      "Iteration 3, loss = 0.00111708\n",
      "Iteration 4, loss = 0.00092321\n",
      "Iteration 5, loss = 0.00068464\n",
      "Iteration 6, loss = 0.00041754\n",
      "Iteration 7, loss = 0.00028100\n",
      "Iteration 8, loss = 0.00024546\n",
      "Iteration 9, loss = 0.00022200\n",
      "Iteration 10, loss = 0.00020497\n",
      "Iteration 11, loss = 0.00019138\n",
      "Iteration 12, loss = 0.00018024\n",
      "Iteration 13, loss = 0.00017087\n",
      "Iteration 14, loss = 0.00016278\n",
      "Iteration 15, loss = 0.00015577\n",
      "Iteration 16, loss = 0.00014953\n",
      "Iteration 17, loss = 0.00014399\n",
      "Iteration 18, loss = 0.00013903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07790982\n",
      "Iteration 2, loss = 0.00861146\n",
      "Iteration 3, loss = 0.00474058\n",
      "Iteration 4, loss = 0.00211874\n",
      "Iteration 5, loss = 0.00101979\n",
      "Iteration 6, loss = 0.00070030\n",
      "Iteration 7, loss = 0.00054868\n",
      "Iteration 8, loss = 0.00051439\n",
      "Iteration 9, loss = 0.00045895\n",
      "Iteration 10, loss = 0.00043623\n",
      "Iteration 11, loss = 0.00037378\n",
      "Iteration 12, loss = 0.00038277\n",
      "Iteration 13, loss = 0.00032875\n",
      "Iteration 14, loss = 0.00034058\n",
      "Iteration 15, loss = 0.00033250\n",
      "Iteration 16, loss = 0.00029204\n",
      "Iteration 17, loss = 0.00032105\n",
      "Iteration 18, loss = 0.00024360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08046637\n",
      "Iteration 2, loss = 0.01052031\n",
      "Iteration 3, loss = 0.00446916\n",
      "Iteration 4, loss = 0.00192345\n",
      "Iteration 5, loss = 0.00088363\n",
      "Iteration 6, loss = 0.00062296\n",
      "Iteration 7, loss = 0.00048951\n",
      "Iteration 8, loss = 0.00040242\n",
      "Iteration 9, loss = 0.00035949\n",
      "Iteration 10, loss = 0.00030801\n",
      "Iteration 11, loss = 0.00028298\n",
      "Iteration 12, loss = 0.00025674\n",
      "Iteration 13, loss = 0.00024478\n",
      "Iteration 14, loss = 0.00022500\n",
      "Iteration 15, loss = 0.00021558\n",
      "Iteration 16, loss = 0.00020084\n",
      "Iteration 17, loss = 0.00019098\n",
      "Iteration 18, loss = 0.00018574\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07595720\n",
      "Iteration 2, loss = 0.00789648\n",
      "Iteration 3, loss = 0.00504027\n",
      "Iteration 4, loss = 0.00249429\n",
      "Iteration 5, loss = 0.00113441\n",
      "Iteration 6, loss = 0.00069265\n",
      "Iteration 7, loss = 0.00051577\n",
      "Iteration 8, loss = 0.00042929\n",
      "Iteration 9, loss = 0.00038288\n",
      "Iteration 10, loss = 0.00031663\n",
      "Iteration 11, loss = 0.00029957\n",
      "Iteration 12, loss = 0.00025767\n",
      "Iteration 13, loss = 0.00024113\n",
      "Iteration 14, loss = 0.00022661\n",
      "Iteration 15, loss = 0.00021437\n",
      "Iteration 16, loss = 0.00020224\n",
      "Iteration 17, loss = 0.00019363\n",
      "Iteration 18, loss = 0.00018756\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07595795\n",
      "Iteration 2, loss = 0.00367575\n",
      "Iteration 3, loss = 0.00257396\n",
      "Iteration 4, loss = 0.00191934\n",
      "Iteration 5, loss = 0.00119599\n",
      "Iteration 6, loss = 0.00065103\n",
      "Iteration 7, loss = 0.00043996\n",
      "Iteration 8, loss = 0.00037656\n",
      "Iteration 9, loss = 0.00031268\n",
      "Iteration 10, loss = 0.00027935\n",
      "Iteration 11, loss = 0.00026033\n",
      "Iteration 12, loss = 0.00023226\n",
      "Iteration 13, loss = 0.00021820\n",
      "Iteration 14, loss = 0.00020527\n",
      "Iteration 15, loss = 0.00019413\n",
      "Iteration 16, loss = 0.00018492\n",
      "Iteration 17, loss = 0.00017805\n",
      "Iteration 18, loss = 0.00017096\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08874703\n",
      "Iteration 2, loss = 0.02012922\n",
      "Iteration 3, loss = 0.01013076\n",
      "Iteration 4, loss = 0.00470877\n",
      "Iteration 5, loss = 0.00290033\n",
      "Iteration 6, loss = 0.00181642\n",
      "Iteration 7, loss = 0.00138088\n",
      "Iteration 8, loss = 0.00099525\n",
      "Iteration 9, loss = 0.00081973\n",
      "Iteration 10, loss = 0.00065072\n",
      "Iteration 11, loss = 0.00054918\n",
      "Iteration 12, loss = 0.00056102\n",
      "Iteration 13, loss = 0.00045373\n",
      "Iteration 14, loss = 0.00040936\n",
      "Iteration 15, loss = 0.00037751\n",
      "Iteration 16, loss = 0.00034304\n",
      "Iteration 17, loss = 0.00032360\n",
      "Iteration 18, loss = 0.00030973\n",
      "Iteration 19, loss = 0.00028903\n",
      "Iteration 20, loss = 0.00027799\n",
      "Iteration 21, loss = 0.00027032\n",
      "Iteration 22, loss = 0.00024804\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.11119720\n",
      "Iteration 2, loss = 0.02670154\n",
      "Iteration 3, loss = 0.01054518\n",
      "Iteration 4, loss = 0.00447676\n",
      "Iteration 5, loss = 0.00254103\n",
      "Iteration 6, loss = 0.00144277\n",
      "Iteration 7, loss = 0.00100644\n",
      "Iteration 8, loss = 0.00080659\n",
      "Iteration 9, loss = 0.00065622\n",
      "Iteration 10, loss = 0.00056578\n",
      "Iteration 11, loss = 0.00049892\n",
      "Iteration 12, loss = 0.00045908\n",
      "Iteration 13, loss = 0.00041678\n",
      "Iteration 14, loss = 0.00038615\n",
      "Iteration 15, loss = 0.00036293\n",
      "Iteration 16, loss = 0.00034144\n",
      "Iteration 17, loss = 0.00032412\n",
      "Iteration 18, loss = 0.00030935\n",
      "Iteration 19, loss = 0.00029677\n",
      "Iteration 20, loss = 0.00028445\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.16287198\n",
      "Iteration 2, loss = 0.03582817\n",
      "Iteration 3, loss = 0.01589103\n",
      "Iteration 4, loss = 0.00768167\n",
      "Iteration 5, loss = 0.00446386\n",
      "Iteration 6, loss = 0.00331508\n",
      "Iteration 7, loss = 0.00223087\n",
      "Iteration 8, loss = 0.00146837\n",
      "Iteration 9, loss = 0.00130789\n",
      "Iteration 10, loss = 0.00107963\n",
      "Iteration 11, loss = 0.00122635\n",
      "Iteration 12, loss = 0.00082988\n",
      "Iteration 13, loss = 0.00076561\n",
      "Iteration 14, loss = 0.00073311\n",
      "Iteration 15, loss = 0.00053960\n",
      "Iteration 16, loss = 0.00050036\n",
      "Iteration 17, loss = 0.00066652\n",
      "Iteration 18, loss = 0.00070157\n",
      "Iteration 19, loss = 0.00058029\n",
      "Iteration 20, loss = 0.00068772\n",
      "Iteration 21, loss = 0.00046182\n",
      "Iteration 22, loss = 0.00037621\n",
      "Iteration 23, loss = 0.00035336\n",
      "Iteration 24, loss = 0.00034243\n",
      "Iteration 25, loss = 0.00033422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07348541\n",
      "Iteration 2, loss = 0.00283901\n",
      "Iteration 3, loss = 0.00144248\n",
      "Iteration 4, loss = 0.00055869\n",
      "Iteration 5, loss = 0.00038388\n",
      "Iteration 6, loss = 0.00031859\n",
      "Iteration 7, loss = 0.00027628\n",
      "Iteration 8, loss = 0.00024680\n",
      "Iteration 9, loss = 0.00022503\n",
      "Iteration 10, loss = 0.00020824\n",
      "Iteration 11, loss = 0.00019443\n",
      "Iteration 12, loss = 0.00018299\n",
      "Iteration 13, loss = 0.00017346\n",
      "Iteration 14, loss = 0.00016517\n",
      "Iteration 15, loss = 0.00015797\n",
      "Iteration 16, loss = 0.00015161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08111346\n",
      "Iteration 2, loss = 0.00766296\n",
      "Iteration 3, loss = 0.00313339\n",
      "Iteration 4, loss = 0.00172780\n",
      "Iteration 5, loss = 0.00098600\n",
      "Iteration 6, loss = 0.00067472\n",
      "Iteration 7, loss = 0.00054889\n",
      "Iteration 8, loss = 0.00048093\n",
      "Iteration 9, loss = 0.00041027\n",
      "Iteration 10, loss = 0.00036306\n",
      "Iteration 11, loss = 0.00040324\n",
      "Iteration 12, loss = 0.00037522\n",
      "Iteration 13, loss = 0.00033174\n",
      "Iteration 14, loss = 0.00029900\n",
      "Iteration 15, loss = 0.00029594\n",
      "Iteration 16, loss = 0.00029249\n",
      "Iteration 17, loss = 0.00048787\n",
      "Iteration 18, loss = 0.00031198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07114034\n",
      "Iteration 2, loss = 0.00108760\n",
      "Iteration 3, loss = 0.00090710\n",
      "Iteration 4, loss = 0.00072305\n",
      "Iteration 5, loss = 0.00052113\n",
      "Iteration 6, loss = 0.00036200\n",
      "Iteration 7, loss = 0.00028247\n",
      "Iteration 8, loss = 0.00024709\n",
      "Iteration 9, loss = 0.00022379\n",
      "Iteration 10, loss = 0.00020630\n",
      "Iteration 11, loss = 0.00019220\n",
      "Iteration 12, loss = 0.00018083\n",
      "Iteration 13, loss = 0.00017117\n",
      "Iteration 14, loss = 0.00016292\n",
      "Iteration 15, loss = 0.00015588\n",
      "Iteration 16, loss = 0.00014927\n",
      "Iteration 17, loss = 0.00014362\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07068583\n",
      "Iteration 2, loss = 0.00134809\n",
      "Iteration 3, loss = 0.00105048\n",
      "Iteration 4, loss = 0.00066675\n",
      "Iteration 5, loss = 0.00033614\n",
      "Iteration 6, loss = 0.00028185\n",
      "Iteration 7, loss = 0.00025087\n",
      "Iteration 8, loss = 0.00022799\n",
      "Iteration 9, loss = 0.00021023\n",
      "Iteration 10, loss = 0.00019589\n",
      "Iteration 11, loss = 0.00018404\n",
      "Iteration 12, loss = 0.00017406\n",
      "Iteration 13, loss = 0.00016549\n",
      "Iteration 14, loss = 0.00015800\n",
      "Iteration 15, loss = 0.00015143\n",
      "Iteration 16, loss = 0.00014552\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07406151\n",
      "Iteration 2, loss = 0.00614279\n",
      "Iteration 3, loss = 0.00479379\n",
      "Iteration 4, loss = 0.00319423\n",
      "Iteration 5, loss = 0.00163421\n",
      "Iteration 6, loss = 0.00080871\n",
      "Iteration 7, loss = 0.00050342\n",
      "Iteration 8, loss = 0.00038793\n",
      "Iteration 9, loss = 0.00032327\n",
      "Iteration 10, loss = 0.00028791\n",
      "Iteration 11, loss = 0.00026049\n",
      "Iteration 12, loss = 0.00023971\n",
      "Iteration 13, loss = 0.00022378\n",
      "Iteration 14, loss = 0.00021030\n",
      "Iteration 15, loss = 0.00019969\n",
      "Iteration 16, loss = 0.00019028\n",
      "Iteration 17, loss = 0.00018217\n",
      "Iteration 18, loss = 0.00017537\n",
      "Iteration 19, loss = 0.00016869\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07193296\n",
      "Iteration 2, loss = 0.00212111\n",
      "Iteration 3, loss = 0.00135392\n",
      "Iteration 4, loss = 0.00078040\n",
      "Iteration 5, loss = 0.00049404\n",
      "Iteration 6, loss = 0.00035037\n",
      "Iteration 7, loss = 0.00029494\n",
      "Iteration 8, loss = 0.00025844\n",
      "Iteration 9, loss = 0.00023466\n",
      "Iteration 10, loss = 0.00021657\n",
      "Iteration 11, loss = 0.00020209\n",
      "Iteration 12, loss = 0.00019010\n",
      "Iteration 13, loss = 0.00018009\n",
      "Iteration 14, loss = 0.00017149\n",
      "Iteration 15, loss = 0.00016393\n",
      "Iteration 16, loss = 0.00015723\n",
      "Iteration 17, loss = 0.00015125\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07830008\n",
      "Iteration 2, loss = 0.00454262\n",
      "Iteration 3, loss = 0.00237393\n",
      "Iteration 4, loss = 0.00187387\n",
      "Iteration 5, loss = 0.00164952\n",
      "Iteration 6, loss = 0.00144799\n",
      "Iteration 7, loss = 0.00145590\n",
      "Iteration 8, loss = 0.00117591\n",
      "Iteration 9, loss = 0.00111843\n",
      "Iteration 10, loss = 0.00103734\n",
      "Iteration 11, loss = 0.00097055\n",
      "Iteration 12, loss = 0.00085438\n",
      "Iteration 13, loss = 0.00086846\n",
      "Iteration 14, loss = 0.00073089\n",
      "Iteration 15, loss = 0.00075349\n",
      "Iteration 16, loss = 0.00061080\n",
      "Iteration 17, loss = 0.00058141\n",
      "Iteration 18, loss = 0.00052088\n",
      "Iteration 19, loss = 0.00058992\n",
      "Iteration 20, loss = 0.00043864\n",
      "Iteration 21, loss = 0.00045242\n",
      "Iteration 22, loss = 0.00047033\n",
      "Iteration 23, loss = 0.00036228\n",
      "Iteration 24, loss = 0.00038338\n",
      "Iteration 25, loss = 0.00033997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.09102377\n",
      "Iteration 2, loss = 0.01097219\n",
      "Iteration 3, loss = 0.00653266\n",
      "Iteration 4, loss = 0.00460379\n",
      "Iteration 5, loss = 0.00364773\n",
      "Iteration 6, loss = 0.00304991\n",
      "Iteration 7, loss = 0.00262802\n",
      "Iteration 8, loss = 0.00210619\n",
      "Iteration 9, loss = 0.00205934\n",
      "Iteration 10, loss = 0.00184336\n",
      "Iteration 11, loss = 0.00164142\n",
      "Iteration 12, loss = 0.00140837\n",
      "Iteration 13, loss = 0.00134790\n",
      "Iteration 14, loss = 0.00107886\n",
      "Iteration 15, loss = 0.00111726\n",
      "Iteration 16, loss = 0.00090914\n",
      "Iteration 17, loss = 0.00078457\n",
      "Iteration 18, loss = 0.00064128\n",
      "Iteration 19, loss = 0.00067166\n",
      "Iteration 20, loss = 0.00073273\n",
      "Iteration 21, loss = 0.00054818\n",
      "Iteration 22, loss = 0.00057055\n",
      "Iteration 23, loss = 0.00049630\n",
      "Iteration 24, loss = 0.00051283\n",
      "Iteration 25, loss = 0.00039280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07085274\n",
      "Iteration 2, loss = 0.00145801\n",
      "Iteration 3, loss = 0.00128334\n",
      "Iteration 4, loss = 0.00106358\n",
      "Iteration 5, loss = 0.00073854\n",
      "Iteration 6, loss = 0.00036859\n",
      "Iteration 7, loss = 0.00028218\n",
      "Iteration 8, loss = 0.00024696\n",
      "Iteration 9, loss = 0.00022362\n",
      "Iteration 10, loss = 0.00020628\n",
      "Iteration 11, loss = 0.00019249\n",
      "Iteration 12, loss = 0.00018120\n",
      "Iteration 13, loss = 0.00017174\n",
      "Iteration 14, loss = 0.00016356\n",
      "Iteration 15, loss = 0.00015648\n",
      "Iteration 16, loss = 0.00015020\n",
      "Iteration 17, loss = 0.00014461\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07536961\n",
      "Iteration 2, loss = 0.00560738\n",
      "Iteration 3, loss = 0.00341936\n",
      "Iteration 4, loss = 0.00181942\n",
      "Iteration 5, loss = 0.00096126\n",
      "Iteration 6, loss = 0.00053302\n",
      "Iteration 7, loss = 0.00039418\n",
      "Iteration 8, loss = 0.00032662\n",
      "Iteration 9, loss = 0.00028526\n",
      "Iteration 10, loss = 0.00025604\n",
      "Iteration 11, loss = 0.00023471\n",
      "Iteration 12, loss = 0.00021887\n",
      "Iteration 13, loss = 0.00020442\n",
      "Iteration 14, loss = 0.00019307\n",
      "Iteration 15, loss = 0.00018363\n",
      "Iteration 16, loss = 0.00017546\n",
      "Iteration 17, loss = 0.00016833\n",
      "Iteration 18, loss = 0.00016208\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.21058582\n",
      "Iteration 2, loss = 0.04333127\n",
      "Iteration 3, loss = 0.01590147\n",
      "Iteration 4, loss = 0.00767871\n",
      "Iteration 5, loss = 0.00454264\n",
      "Iteration 6, loss = 0.00286624\n",
      "Iteration 7, loss = 0.00229650\n",
      "Iteration 8, loss = 0.00188949\n",
      "Iteration 9, loss = 0.00187311\n",
      "Iteration 10, loss = 0.00135667\n",
      "Iteration 11, loss = 0.00160071\n",
      "Iteration 12, loss = 0.00102812\n",
      "Iteration 13, loss = 0.00101900\n",
      "Iteration 14, loss = 0.00081796\n",
      "Iteration 15, loss = 0.00060024\n",
      "Iteration 16, loss = 0.00055682\n",
      "Iteration 17, loss = 0.00069064\n",
      "Iteration 18, loss = 0.00080990\n",
      "Iteration 19, loss = 0.00067874\n",
      "Iteration 20, loss = 0.00088210\n",
      "Iteration 21, loss = 0.00054642\n",
      "Iteration 22, loss = 0.00042358\n",
      "Iteration 23, loss = 0.00039816\n",
      "Iteration 24, loss = 0.00038628\n",
      "Iteration 25, loss = 0.00037519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.07414806\n",
      "Iteration 2, loss = 0.00413896\n",
      "Iteration 3, loss = 0.00266879\n",
      "Iteration 4, loss = 0.00133633\n",
      "Iteration 5, loss = 0.00059707\n",
      "Iteration 6, loss = 0.00044180\n",
      "Iteration 7, loss = 0.00034371\n",
      "Iteration 8, loss = 0.00030847\n",
      "Iteration 9, loss = 0.00027819\n",
      "Iteration 10, loss = 0.00024110\n",
      "Iteration 11, loss = 0.00022556\n",
      "Iteration 12, loss = 0.00020869\n",
      "Iteration 13, loss = 0.00019526\n",
      "Iteration 14, loss = 0.00018451\n",
      "Iteration 15, loss = 0.00017532\n",
      "Iteration 16, loss = 0.00016834\n",
      "Iteration 17, loss = 0.00016120\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.12103519\n",
      "Iteration 2, loss = 0.03625574\n",
      "Iteration 3, loss = 0.01273591\n",
      "Iteration 4, loss = 0.00603161\n",
      "Iteration 5, loss = 0.00348386\n",
      "Iteration 6, loss = 0.00231529\n",
      "Iteration 7, loss = 0.00170308\n",
      "Iteration 8, loss = 0.00137648\n",
      "Iteration 9, loss = 0.00114382\n",
      "Iteration 10, loss = 0.00083520\n",
      "Iteration 11, loss = 0.00073493\n",
      "Iteration 12, loss = 0.00063909\n",
      "Iteration 13, loss = 0.00055647\n",
      "Iteration 14, loss = 0.00050973\n",
      "Iteration 15, loss = 0.00050887\n",
      "Iteration 16, loss = 0.00046814\n",
      "Iteration 17, loss = 0.00039961\n",
      "Iteration 18, loss = 0.00037959\n",
      "Iteration 19, loss = 0.00034847\n",
      "Iteration 20, loss = 0.00033403\n",
      "Iteration 21, loss = 0.00031990\n",
      "Iteration 22, loss = 0.00030842\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07839992\n",
      "Iteration 2, loss = 0.00645272\n",
      "Iteration 3, loss = 0.00226052\n",
      "Iteration 4, loss = 0.00096081\n",
      "Iteration 5, loss = 0.00059911\n",
      "Iteration 6, loss = 0.00039123\n",
      "Iteration 7, loss = 0.00032575\n",
      "Iteration 8, loss = 0.00028395\n",
      "Iteration 9, loss = 0.00025520\n",
      "Iteration 10, loss = 0.00023377\n",
      "Iteration 11, loss = 0.00021697\n",
      "Iteration 12, loss = 0.00020325\n",
      "Iteration 13, loss = 0.00019204\n",
      "Iteration 14, loss = 0.00018249\n",
      "Iteration 15, loss = 0.00017403\n",
      "Iteration 16, loss = 0.00016678\n",
      "Iteration 17, loss = 0.00016025\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07579980\n",
      "Iteration 2, loss = 0.00792408\n",
      "Iteration 3, loss = 0.00568716\n",
      "Iteration 4, loss = 0.00324664\n",
      "Iteration 5, loss = 0.00166969\n",
      "Iteration 6, loss = 0.00092116\n",
      "Iteration 7, loss = 0.00059908\n",
      "Iteration 8, loss = 0.00046035\n",
      "Iteration 9, loss = 0.00039348\n",
      "Iteration 10, loss = 0.00034037\n",
      "Iteration 11, loss = 0.00029778\n",
      "Iteration 12, loss = 0.00027187\n",
      "Iteration 13, loss = 0.00025135\n",
      "Iteration 14, loss = 0.00023321\n",
      "Iteration 15, loss = 0.00022093\n",
      "Iteration 16, loss = 0.00020626\n",
      "Iteration 17, loss = 0.00019776\n",
      "Iteration 18, loss = 0.00018906\n",
      "Iteration 19, loss = 0.00017989\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07207970\n",
      "Iteration 2, loss = 0.00409060\n",
      "Iteration 3, loss = 0.00281092\n",
      "Iteration 4, loss = 0.00149557\n",
      "Iteration 5, loss = 0.00062019\n",
      "Iteration 6, loss = 0.00039423\n",
      "Iteration 7, loss = 0.00032166\n",
      "Iteration 8, loss = 0.00027925\n",
      "Iteration 9, loss = 0.00024926\n",
      "Iteration 10, loss = 0.00022768\n",
      "Iteration 11, loss = 0.00021101\n",
      "Iteration 12, loss = 0.00019761\n",
      "Iteration 13, loss = 0.00018650\n",
      "Iteration 14, loss = 0.00017705\n",
      "Iteration 15, loss = 0.00016889\n",
      "Iteration 16, loss = 0.00016183\n",
      "Iteration 17, loss = 0.00015555\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.15130863\n",
      "Iteration 2, loss = 0.01086623\n",
      "Iteration 3, loss = 0.00498925\n",
      "Iteration 4, loss = 0.00252789\n",
      "Iteration 5, loss = 0.00135997\n",
      "Iteration 6, loss = 0.00098160\n",
      "Iteration 7, loss = 0.00073780\n",
      "Iteration 8, loss = 0.00060370\n",
      "Iteration 9, loss = 0.00052188\n",
      "Iteration 10, loss = 0.00042389\n",
      "Iteration 11, loss = 0.00038785\n",
      "Iteration 12, loss = 0.00035433\n",
      "Iteration 13, loss = 0.00033198\n",
      "Iteration 14, loss = 0.00030834\n",
      "Iteration 15, loss = 0.00029386\n",
      "Iteration 16, loss = 0.00027840\n",
      "Iteration 17, loss = 0.00026534\n",
      "Iteration 18, loss = 0.00025640\n",
      "Iteration 19, loss = 0.00024732\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07460025\n",
      "Iteration 2, loss = 0.00736241\n",
      "Iteration 3, loss = 0.00482594\n",
      "Iteration 4, loss = 0.00266171\n",
      "Iteration 5, loss = 0.00111311\n",
      "Iteration 6, loss = 0.00059728\n",
      "Iteration 7, loss = 0.00043696\n",
      "Iteration 8, loss = 0.00035796\n",
      "Iteration 9, loss = 0.00030950\n",
      "Iteration 10, loss = 0.00027644\n",
      "Iteration 11, loss = 0.00025267\n",
      "Iteration 12, loss = 0.00023456\n",
      "Iteration 13, loss = 0.00021895\n",
      "Iteration 14, loss = 0.00020697\n",
      "Iteration 15, loss = 0.00019638\n",
      "Iteration 16, loss = 0.00018776\n",
      "Iteration 17, loss = 0.00017959\n",
      "Iteration 18, loss = 0.00017272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.12464574\n",
      "Iteration 2, loss = 0.02213277\n",
      "Iteration 3, loss = 0.01047735\n",
      "Iteration 4, loss = 0.00590444\n",
      "Iteration 5, loss = 0.00408099\n",
      "Iteration 6, loss = 0.00260972\n",
      "Iteration 7, loss = 0.00190132\n",
      "Iteration 8, loss = 0.00161080\n",
      "Iteration 9, loss = 0.00141752\n",
      "Iteration 10, loss = 0.00104446\n",
      "Iteration 11, loss = 0.00080941\n",
      "Iteration 12, loss = 0.00068792\n",
      "Iteration 13, loss = 0.00054300\n",
      "Iteration 14, loss = 0.00049983\n",
      "Iteration 15, loss = 0.00045302\n",
      "Iteration 16, loss = 0.00039793\n",
      "Iteration 17, loss = 0.00036996\n",
      "Iteration 18, loss = 0.00033750\n",
      "Iteration 19, loss = 0.00031694\n",
      "Iteration 20, loss = 0.00030257\n",
      "Iteration 21, loss = 0.00028537\n",
      "Iteration 22, loss = 0.00027374\n",
      "Iteration 23, loss = 0.00026149\n",
      "Iteration 24, loss = 0.00025077\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08490220\n",
      "Iteration 2, loss = 0.00886029\n",
      "Iteration 3, loss = 0.00409987\n",
      "Iteration 4, loss = 0.00179993\n",
      "Iteration 5, loss = 0.00096145\n",
      "Iteration 6, loss = 0.00064925\n",
      "Iteration 7, loss = 0.00049896\n",
      "Iteration 8, loss = 0.00041224\n",
      "Iteration 9, loss = 0.00035652\n",
      "Iteration 10, loss = 0.00031280\n",
      "Iteration 11, loss = 0.00028262\n",
      "Iteration 12, loss = 0.00025922\n",
      "Iteration 13, loss = 0.00024398\n",
      "Iteration 14, loss = 0.00022520\n",
      "Iteration 15, loss = 0.00021317\n",
      "Iteration 16, loss = 0.00020184\n",
      "Iteration 17, loss = 0.00019291\n",
      "Iteration 18, loss = 0.00018498\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.09935667\n",
      "Iteration 2, loss = 0.02103441\n",
      "Iteration 3, loss = 0.01069748\n",
      "Iteration 4, loss = 0.00551657\n",
      "Iteration 5, loss = 0.00301077\n",
      "Iteration 6, loss = 0.00204644\n",
      "Iteration 7, loss = 0.00158339\n",
      "Iteration 8, loss = 0.00140522\n",
      "Iteration 9, loss = 0.00110867\n",
      "Iteration 10, loss = 0.00092623\n",
      "Iteration 11, loss = 0.00074912\n",
      "Iteration 12, loss = 0.00072539\n",
      "Iteration 13, loss = 0.00053338\n",
      "Iteration 14, loss = 0.00048075\n",
      "Iteration 15, loss = 0.00057420\n",
      "Iteration 16, loss = 0.00047705\n",
      "Iteration 17, loss = 0.00037637\n",
      "Iteration 18, loss = 0.00034244\n",
      "Iteration 19, loss = 0.00031093\n",
      "Iteration 20, loss = 0.00029468\n",
      "Iteration 21, loss = 0.00027945\n",
      "Iteration 22, loss = 0.00027268\n",
      "Iteration 23, loss = 0.00025644\n",
      "Iteration 24, loss = 0.00024746\n",
      "Iteration 25, loss = 0.00023962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.08158331\n",
      "Iteration 2, loss = 0.01264966\n",
      "Iteration 3, loss = 0.00761395\n",
      "Iteration 4, loss = 0.00384425\n",
      "Iteration 5, loss = 0.00168470\n",
      "Iteration 6, loss = 0.00098870\n",
      "Iteration 7, loss = 0.00072080\n",
      "Iteration 8, loss = 0.00056948\n",
      "Iteration 9, loss = 0.00046797\n",
      "Iteration 10, loss = 0.00040817\n",
      "Iteration 11, loss = 0.00035866\n",
      "Iteration 12, loss = 0.00033060\n",
      "Iteration 13, loss = 0.00029657\n",
      "Iteration 14, loss = 0.00027883\n",
      "Iteration 15, loss = 0.00026105\n",
      "Iteration 16, loss = 0.00024703\n",
      "Iteration 17, loss = 0.00022890\n",
      "Iteration 18, loss = 0.00022152\n",
      "Iteration 19, loss = 0.00021140\n",
      "Iteration 20, loss = 0.00020110\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07273031\n",
      "Iteration 2, loss = 0.00339290\n",
      "Iteration 3, loss = 0.00271003\n",
      "Iteration 4, loss = 0.00179358\n",
      "Iteration 5, loss = 0.00110392\n",
      "Iteration 6, loss = 0.00066577\n",
      "Iteration 7, loss = 0.00046275\n",
      "Iteration 8, loss = 0.00037353\n",
      "Iteration 9, loss = 0.00031279\n",
      "Iteration 10, loss = 0.00027848\n",
      "Iteration 11, loss = 0.00024998\n",
      "Iteration 12, loss = 0.00023125\n",
      "Iteration 13, loss = 0.00021155\n",
      "Iteration 14, loss = 0.00019962\n",
      "Iteration 15, loss = 0.00018799\n",
      "Iteration 16, loss = 0.00017871\n",
      "Iteration 17, loss = 0.00017115\n",
      "Iteration 18, loss = 0.00016352\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.07214471\n",
      "Iteration 2, loss = 0.00350449\n",
      "Iteration 3, loss = 0.00277057\n",
      "Iteration 4, loss = 0.00206742\n",
      "Iteration 5, loss = 0.00144492\n",
      "Iteration 6, loss = 0.00089148\n",
      "Iteration 7, loss = 0.00056507\n",
      "Iteration 8, loss = 0.00043742\n",
      "Iteration 9, loss = 0.00037264\n",
      "Iteration 10, loss = 0.00032179\n",
      "Iteration 11, loss = 0.00028195\n",
      "Iteration 12, loss = 0.00025807\n",
      "Iteration 13, loss = 0.00023468\n",
      "Iteration 14, loss = 0.00022099\n",
      "Iteration 15, loss = 0.00020433\n",
      "Iteration 16, loss = 0.00019543\n",
      "Iteration 17, loss = 0.00018365\n",
      "Iteration 18, loss = 0.00017579\n",
      "Iteration 19, loss = 0.00016815\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.08584540\n",
      "Iteration 2, loss = 0.00542498\n",
      "Iteration 3, loss = 0.00169422\n",
      "Iteration 4, loss = 0.00087055\n",
      "Iteration 5, loss = 0.00047277\n",
      "Iteration 6, loss = 0.00037223\n",
      "Iteration 7, loss = 0.00031678\n",
      "Iteration 8, loss = 0.00028026\n",
      "Iteration 9, loss = 0.00025382\n",
      "Iteration 10, loss = 0.00023369\n",
      "Iteration 11, loss = 0.00021761\n",
      "Iteration 12, loss = 0.00020454\n",
      "Iteration 13, loss = 0.00019358\n",
      "Iteration 14, loss = 0.00018414\n",
      "Iteration 15, loss = 0.00017592\n",
      "Iteration 16, loss = 0.00016873\n",
      "Iteration 17, loss = 0.00016232\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                              hidden_layer_sizes=(120, 120),\n",
       "                                              learning_rate=&#x27;adaptive&#x27;,\n",
       "                                              max_iter=25, random_state=42,\n",
       "                                              verbose=True))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                              hidden_layer_sizes=(120, 120),\n",
       "                                              learning_rate=&#x27;adaptive&#x27;,\n",
       "                                              max_iter=25, random_state=42,\n",
       "                                              verbose=True))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(120, 120),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=25, random_state=42,\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(120, 120),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=25, random_state=42,\n",
       "              verbose=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=MLPClassifier(activation='tanh',\n",
       "                                              hidden_layer_sizes=(120, 120),\n",
       "                                              learning_rate='adaptive',\n",
       "                                              max_iter=25, random_state=42,\n",
       "                                              verbose=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the MLP classifier with specified parameters\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(120, 120), max_iter=25, activation='tanh', solver='adam', random_state=42, learning_rate='adaptive', verbose=True)\n",
    "\n",
    "# Create a MultiOutputClassifier to handle multi-output classification\n",
    "classifier = MultiOutputClassifier(mlp)\n",
    "\n",
    "# Fit the MultiOutputClassifier using the TF-IDF matrix for text and 'y_train'\n",
    "classifier.fit(X_train_idf_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the trained multi-output classifier\n",
    "y_pred = classifier.predict(X_test_idf_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame with predicted values and column names\n",
    "column_names = y_train.columns\n",
    "pd_pred = pd.DataFrame(y_pred, columns=column_names)\n",
    "\n",
    "# Specify the file path where you want to save the CSV\n",
    "file_path = \"day3.csv\"\n",
    "\n",
    "# Convert the DataFrame to CSV and save the CSV file\n",
    "pd_pred.to_csv(file_path, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
